{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning class exercise list 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data_size, train_val_split = 0.1):\n",
    "    X = np.zeros((data_size, 3),dtype=np.float128)\n",
    "    y = np.zeros((data_size, 8),dtype=np.float128)\n",
    "    for i in range(data_size):\n",
    "        arr = np.random.randint(0, 2, 3) + np.random.uniform(-0.1,0.1, 3)\n",
    "        X[i] = np.round(arr,4)\n",
    "        y[i][int(round(arr[0]) * 4 + round(arr[1]) * 2+ round(arr[2]))] = 1\n",
    "    \n",
    "    val_split = round(data_size * (1 - train_val_split))\n",
    "\n",
    "    X_train, y_train = X[:val_split].T, y[:val_split].T\n",
    "    X_val, y_val = X[val_split:].T, y[val_split:].T\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(value):\n",
    "    return 1/(1 + np.exp(-value))\n",
    "\n",
    "def sigmoid_derivative(value):\n",
    "    return sigmoid(value) * (1 - sigmoid(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(value):\n",
    "    expA = np.exp(value.T - np.max(value.T, axis=1, keepdims=True))\n",
    "    return (expA / expA.sum(axis=1, keepdims=True)).T\n",
    "\n",
    "def softmax_derivative(value):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(value):\n",
    "    return np.maximum(value, 0)\n",
    "\n",
    "def relu_derivative(value):\n",
    "    value[relu(value) <=0] = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially Weighted Average\n",
    "$$\n",
    "V_{10} = \\frac{0.1\\theta_{10} + 0.9\\cdot0.1\\theta_{9} + 0.9^2\\cdot0.1\\theta_{8} + \\cdots + 0.9^8\\cdot0.1\\theta_{2} + 0.9^9\\cdot0.1\\theta_{1}}{10}\n",
    "$$\n",
    "* This is how we usually compute an average. Although, having to keep all theses values in memory is costly. One alternative way would be to compute $V_{10}$ taking into account only $V_9$ and $\\theta_{10}$.\n",
    "$$\n",
    "V_{10} = \\frac{9}{10}V_9 + \\frac{1}{10}\\theta_{10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which can be modelled as:\n",
    "$$\n",
    "V_t = \\beta V_{t-1} + (1 - \\beta) \\theta_t\n",
    "$$\n",
    "Where $\\beta$ is calculled as $\\frac{t -1}{t}$  \n",
    "the time window can be calculed through having the value of $\\beta$ as $\\frac{1}{1 - \\beta}$ days/windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In early training, we have to do a bias correction in this averaging, in order to compensate the lack of data in previous time steps inserted on the time window. At time step 0, if working with a 0.9 $\\beta$, we will have a \n",
    "time window of 10, but our estimates will be biased and far from the real cause it will lack more terms that should make a parte of the exponentially weighted average. In order to fix this, we divide the $V$ value calculated by (1 - $\\beta^t$) which will \"normalize\" the initial values and wont affect the values the other ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "V_t = \\frac{V_t}{1 - \\beta^t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes your class:\n",
    "            parameters : dictionary of parameters, which will store W and b through propagation.\n",
    "            cache : dictionary of cache, which will be responsible for storing A and Z during the propagation.\n",
    "            grads: dictionary of gradients, which will store all gradients computed during backprop.\n",
    "            v : dictionary with momentum ewa estimates\n",
    "            s : dictionary with RMSprop ewa estimates\n",
    "        Args:\n",
    "            No arguments taken.\n",
    "        return:\n",
    "            No return.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.parameters = {}\n",
    "        self.cache = {}\n",
    "        self.grads = {}\n",
    "        self.v = {}\n",
    "        self.s = {}\n",
    "\n",
    "    def fit(self, X_train, y_train, hidden=relu, output=softmax):\n",
    "        \"\"\"\n",
    "        Args : \n",
    "            X_train = input data of shape (n_x, number_of_examples).\n",
    "            y_train = label vector of shape (n_y, number_of_examples).\n",
    "            hidden : passed as argument the function used on the hidden layers\n",
    "            output : function used on output layer\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.m = X_train.shape[1]\n",
    "        self.hidden = hidden # function passed as argument to be used on hidden layers\n",
    "        self.output = output # function passed as argument to be used on output layers\n",
    "        \n",
    "        if self.output == sigmoid:\n",
    "            self.output_derivative = sigmoid_derivative\n",
    "        elif self.output == softmax:\n",
    "            self.output_derivative = softmax_derivative\n",
    "        else:\n",
    "            print(\"output activation not recognized\")\n",
    "            return -1\n",
    "        \n",
    "        if self.hidden == relu:\n",
    "            self.hidden_derivative = relu_derivative\n",
    "        elif self.hidden == sigmoid:\n",
    "            self.hidden_derivative = sigmoid_derivative\n",
    "        else:\n",
    "            print(\"hidden activation not recognized\")\n",
    "            return -1\n",
    "    \n",
    "    def initialize_parameters(self, dims, adam_optimizer=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dims = dimensions of the network.\n",
    "            \n",
    "            Example:\n",
    "                dims = [3,3,8]\n",
    "                \n",
    "                A network with input size = 3, hidden layer = 3 and output layer = 8.\n",
    "                \n",
    "                The first dimension on the list must always be the length of each example.\n",
    "                The last dimension on the list must always be the length of each output example.\n",
    "                \n",
    "                In a case where X_train shape = (3, 4500) and y_train shape = (8, 4500), 4500 in\n",
    "                each shape represents the number of examples.\n",
    "                \n",
    "                dims = [3, 8]\n",
    "        Return:\n",
    "            parameters : a dictionary containing all weights and biases intialized\n",
    "                \n",
    "        \"\"\"\n",
    "        self.L = len(dims)\n",
    "        for l in range(1, self.L):\n",
    "            self.parameters[\"W\" + str(l)] = np.random.randn(dims[l], dims[l-1]) * 0.01\n",
    "            self.parameters[\"b\" + str(l)] = np.zeros((dims[l], 1))\n",
    "            if adam_optimizer:\n",
    "                self.v[\"VdW\" + str(l)] = np.zeros((dims[l], dims[l-1]))\n",
    "                self.v[\"Vdb\" + str(l)] = np.zeros((dims[l], 1))\n",
    "                self.s[\"SdW\" + str(l)] = np.zeros((dims[l], dims[l-1]))\n",
    "                self.s[\"Sdb\" + str(l)] = np.zeros((dims[l], 1))\n",
    "        return self.parameters\n",
    "    \n",
    "    def propagate(self, X):\n",
    "        \"\"\"\n",
    "        Does the forward propagation of the network\n",
    "        \"\"\"\n",
    "        A_prev = X\n",
    "        self.cache[f\"A{0}\"] = A_prev\n",
    "        for l in range(1, self.L):\n",
    "            \n",
    "            Z = np.dot(self.parameters[f\"W{l}\"], A_prev) + self.parameters[f\"b{l}\"]\n",
    "\n",
    "            if l == self.L - 1:\n",
    "                A = self.output(Z)\n",
    "            else:\n",
    "                A = self.hidden(Z)\n",
    "\n",
    "            self.cache[f\"Z{l}\"] = Z\n",
    "            self.cache[f\"A{l}\"] = A\n",
    "            \n",
    "            A_prev = A\n",
    "        \n",
    "        self.y_hat = A\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the value using the propagate function\n",
    "        \n",
    "        Args:\n",
    "            X : data to be used on prediction\n",
    "        Return:\n",
    "            y_hat : data predicted\n",
    "        \"\"\"\n",
    "        self.propagate(X)\n",
    "        return self.y_hat\n",
    "    \n",
    "    def compute_cost(self):\n",
    "        pred = self.y_hat.T\n",
    "        real = self.y_train.T\n",
    "        n_samples = real.shape[0]\n",
    "        logp = - np.log(pred[np.arange(n_samples), real.argmax(axis=1)])\n",
    "        cost = np.sum(logp)/(n_samples)\n",
    "        return cost\n",
    "\n",
    "    def loss(self):\n",
    "        res = self.y_hat - self.y_train\n",
    "        return res\n",
    "\n",
    "    def backprop(self):\n",
    "        dA = self.loss()\n",
    "        \n",
    "        dZ = dA * self.output_derivative(self.cache[f\"Z{self.L - 1}\"])\n",
    "        \n",
    "        self.grads[f\"dW{self.L - 1}\"] = 1/self.m * (np.dot(dZ, self.cache[f\"A{self.L - 2}\"].T))\n",
    "        self.grads[f\"db{self.L - 1}\"] = 1/self.m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        \n",
    "        \n",
    "        for l in reversed(range(1, self.L - 1)):\n",
    "            self.grads[f\"dA_prev{l}\"] = np.dot(self.parameters[f\"W{l + 1}\"].T,dZ)\n",
    "            dZ = self.grads[f\"dA_prev{l}\"] * self.hidden_derivative(self.cache[f\"Z{l}\"])\n",
    "            self.grads[f\"dW{l}\"] = 1/self.m * (np.dot(dZ, self.cache[f\"A{l - 1}\"].T))\n",
    "            self.grads[f\"db{l}\"] = 1/self.m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    \n",
    "    def update_grads_adam(self, t, learning_rate = 0.01, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8):\n",
    "        \"\"\"\n",
    "        ADAM -> Adaptive Moment estimation\n",
    "        Args:\n",
    "            t : epoch number\n",
    "            learning_rate : learning rate chosed to upgrade weights\n",
    "            beta1 : exponentially weighted average used on v (momentum), beta1 = 0.9 (recommended on paper) is approx 10 days ewa\n",
    "            beta1 : exponentially weighted average used on s (RMSprop), beta2 = 0.999 (recommended on paper)\n",
    "            epsilon : term to prevent division by zero\n",
    "        \"\"\"\n",
    "        \n",
    "        v_biasCorrected = {}\n",
    "        s_biasCorrected = {}\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        for l in reversed(range(1, self.L)):\n",
    "            # moving average of the gradients\n",
    "            self.v[f\"VdW{l}\"] = beta1 * self.v[f\"VdW{l}\"] + (1 - beta1)* self.grads[f\"dW{l}\"]\n",
    "            self.v[f\"Vdb{l}\"] = beta1 * self.v[f\"Vdb{l}\"] + (1 - beta1)* self.grads[f\"db{l}\"]\n",
    "\n",
    "            v_biasCorrected[f\"VdW{l}\"] = self.v[f\"VdW{l}\"]/(1 - beta1 ** t) # bias correction to the first updates\n",
    "            v_biasCorrected[f\"Vdb{l}\"] = self.v[f\"Vdb{l}\"]/(1 - beta1 ** t) # bias correction\n",
    "\n",
    "            self.s[f\"SdW{l}\"] = beta2 * self.s[f\"SdW{l}\"] + (1 - beta2) * np.square(self.grads[f\"dW{l}\"])\n",
    "            self.s[f\"Sdb{l}\"] = beta2 * self.s[f\"Sdb{l}\"] + (1 - beta2) * np.square(self.grads[f\"db{l}\"])\n",
    "                                                                                             \n",
    "            s_biasCorrected[f\"SdW{l}\"] = self.s[f\"SdW{l}\"]/(1 - beta2 ** t) # bias correction to the first updates\n",
    "            s_biasCorrected[f\"Sdb{l}\"] = self.s[f\"Sdb{l}\"]/(1 - beta2 ** t) # bias correction\n",
    "            \n",
    "            self.parameters[f\"W{l}\"] -= self.learning_rate * (v_biasCorrected[f\"VdW{l}\"])/(np.sqrt(s_biasCorrected[f\"SdW{l}\"]) + epsilon)\n",
    "            self.parameters[f\"b{l}\"] -= self.learning_rate * (v_biasCorrected[f\"Vdb{l}\"])/(np.sqrt(s_biasCorrected[f\"Sdb{l}\"]) + epsilon)\n",
    "                                                                                               \n",
    "    def update_grads_gd(self, learning_rate = 0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            learning_rate : learning rate chosed to upgrade weights\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        for l in reversed(range(1, self.L)):\n",
    "            self.parameters[f\"W{l}\"] -= self.learning_rate * (self.grads[f\"dW{l}\"])\n",
    "            self.parameters[f\"b{l}\"] -= self.learning_rate * (self.grads[f\"db{l}\"])\n",
    "\n",
    "    def train(self, dims, learning_rate = 0.01, iterations = 1000, adam_optimizer=False):\n",
    "        if iterations > 100:\n",
    "            printing_interval = round(iterations * 0.01)\n",
    "        else:\n",
    "            printing_interval = 1\n",
    "        self.initialize_parameters(dims, adam_optimizer=adam_optimizer)\n",
    "        costs = []\n",
    "        for i in range(iterations):\n",
    "            self.propagate(self.X_train)\n",
    "            cost = self.compute_cost()\n",
    "            if i % printing_interval == 0:\n",
    "                print(f\"epoch {i} : {cost}\")\n",
    "            costs.append(cost)\n",
    "            self.backprop()\n",
    "            if adam_optimizer:\n",
    "                self.update_grads_adam(t=i+1, learning_rate=learning_rate)\n",
    "            else:\n",
    "                self.update_grads_gd(learning_rate = learning_rate)\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per hundreds)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val , y_train, y_val = generate_data(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = DNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 2.0822960619623117\n",
      "epoch 4 : 1.562271564595699\n",
      "epoch 8 : 1.1647866878601822\n",
      "epoch 12 : 0.8721443738090497\n",
      "epoch 16 : 0.6592282948196263\n",
      "epoch 20 : 0.5053467408211979\n",
      "epoch 24 : 0.39570660192460255\n",
      "epoch 28 : 0.3176467161044149\n",
      "epoch 32 : 0.26141312080595236\n",
      "epoch 36 : 0.2198849983299908\n",
      "epoch 40 : 0.18853779806225593\n",
      "epoch 44 : 0.1644752363877394\n",
      "epoch 48 : 0.1456580707168918\n",
      "epoch 52 : 0.13066083952444693\n",
      "epoch 56 : 0.11845456320716033\n",
      "epoch 60 : 0.10833297744665674\n",
      "epoch 64 : 0.09979870271547937\n",
      "epoch 68 : 0.0925002345159666\n",
      "epoch 72 : 0.08618017090438514\n",
      "epoch 76 : 0.08064507412744558\n",
      "epoch 80 : 0.07574921038784457\n",
      "epoch 84 : 0.07138108839399522\n",
      "epoch 88 : 0.06745455223435247\n",
      "epoch 92 : 0.06390230872906333\n",
      "epoch 96 : 0.060671090909340204\n",
      "epoch 100 : 0.057717840517462135\n",
      "epoch 104 : 0.05500730771828038\n",
      "epoch 108 : 0.05251034252735541\n",
      "epoch 112 : 0.050202528767373404\n",
      "epoch 116 : 0.04806321737290407\n",
      "epoch 120 : 0.04607480885574349\n",
      "epoch 124 : 0.04422217534732521\n",
      "epoch 128 : 0.042492210683962826\n",
      "epoch 132 : 0.040873483224076766\n",
      "epoch 136 : 0.039355963635538845\n",
      "epoch 140 : 0.03793080495247245\n",
      "epoch 144 : 0.03659016610707677\n",
      "epoch 148 : 0.035327068770504\n",
      "epoch 152 : 0.034135278590307606\n",
      "epoch 156 : 0.03300920645969598\n",
      "epoch 160 : 0.031943825882565335\n",
      "epoch 164 : 0.030934603029799335\n",
      "epoch 168 : 0.029977437273888158\n",
      "epoch 172 : 0.029068610440003015\n",
      "epoch 176 : 0.0282047431806833\n",
      "epoch 180 : 0.02738275729870176\n",
      "epoch 184 : 0.026599843062824056\n",
      "epoch 188 : 0.025853430729812436\n",
      "epoch 192 : 0.025141165651753578\n",
      "epoch 196 : 0.024460886435515757\n",
      "epoch 200 : 0.02381060571198552\n",
      "epoch 204 : 0.02318849315798818\n",
      "epoch 208 : 0.02259286046817763\n",
      "epoch 212 : 0.022022148015945788\n",
      "epoch 216 : 0.02147491298374814\n",
      "epoch 220 : 0.020949818777757832\n",
      "epoch 224 : 0.020445625567174316\n",
      "epoch 228 : 0.019961181810621814\n",
      "epoch 232 : 0.019495416651612238\n",
      "epoch 236 : 0.019047333080955995\n",
      "epoch 240 : 0.01861600177746111\n",
      "epoch 244 : 0.01820055554989791\n",
      "epoch 248 : 0.017800184313077467\n",
      "epoch 252 : 0.017414130539316536\n",
      "epoch 256 : 0.017041685133836037\n",
      "epoch 260 : 0.016682183688919994\n",
      "epoch 264 : 0.0163350030770704\n",
      "epoch 268 : 0.015999558348080346\n",
      "epoch 272 : 0.01567529989903238\n",
      "epoch 276 : 0.015361710889784642\n",
      "epoch 280 : 0.015058304879604491\n",
      "epoch 284 : 0.014764623663319383\n",
      "epoch 288 : 0.014480235287732233\n",
      "epoch 292 : 0.014204732231136039\n",
      "epoch 296 : 0.01393772973059832\n",
      "epoch 300 : 0.01367886424330449\n",
      "epoch 304 : 0.013427792029678155\n",
      "epoch 308 : 0.01318418784726033\n",
      "epoch 312 : 0.012947743745449129\n",
      "epoch 316 : 0.012718167952195207\n",
      "epoch 320 : 0.012495183844631287\n",
      "epoch 324 : 0.012278528996400301\n",
      "epoch 328 : 0.012067954295147228\n",
      "epoch 332 : 0.011863223124265226\n",
      "epoch 336 : 0.011664110603545894\n",
      "epoch 340 : 0.011470402883883873\n",
      "epoch 344 : 0.011281896491634755\n",
      "epoch 348 : 0.011098397718627796\n",
      "epoch 352 : 0.01091972205419684\n",
      "epoch 356 : 0.010745693655918268\n",
      "epoch 360 : 0.010576144856038068\n",
      "epoch 364 : 0.010410915700834598\n",
      "epoch 368 : 0.010249853520402289\n",
      "epoch 372 : 0.010092812526557427\n",
      "epoch 376 : 0.009939653436762346\n",
      "epoch 380 : 0.009790243122141343\n",
      "epoch 384 : 0.009644454277821927\n",
      "epoch 388 : 0.009502165113980686\n",
      "epoch 392 : 0.009363259066105294\n",
      "epoch 396 : 0.00922762452310449\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network.train([X_train.shape[0], y_train.shape[0]], iterations=400, learning_rate=0.1, adam_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 2.0794728652942873\n",
      "epoch 40 : 2.078919856063855\n",
      "epoch 80 : 2.078667586252647\n",
      "epoch 120 : 2.0785207667056063\n",
      "epoch 160 : 2.07840528661267\n",
      "epoch 200 : 2.0782902707687403\n",
      "epoch 240 : 2.078159131478085\n",
      "epoch 280 : 2.0779984089410566\n",
      "epoch 320 : 2.077792982667329\n",
      "epoch 360 : 2.07752157172426\n",
      "epoch 400 : 2.0771438692832396\n",
      "epoch 440 : 2.0765879813538954\n",
      "epoch 480 : 2.0757258648689674\n",
      "epoch 520 : 2.0742983734336558\n",
      "epoch 560 : 2.0717038095271607\n",
      "epoch 600 : 2.066429292575302\n",
      "epoch 640 : 2.054069546671953\n",
      "epoch 680 : 2.0211522336097874\n",
      "epoch 720 : 1.9420410004056543\n",
      "epoch 760 : 1.7859745083801384\n",
      "epoch 800 : 1.4726056232435702\n",
      "epoch 840 : 1.1396803772741235\n",
      "epoch 880 : 0.904200765803087\n",
      "epoch 920 : 0.7383406961452554\n",
      "epoch 960 : 0.6120821208085196\n",
      "epoch 1000 : 0.7682731128247161\n",
      "epoch 1040 : 0.5008986996776318\n",
      "epoch 1080 : 0.2857605731744577\n",
      "epoch 1120 : 0.16750987273309798\n",
      "epoch 1160 : 0.11798100469807764\n",
      "epoch 1200 : 0.08906606956942333\n",
      "epoch 1240 : 0.07100247285324\n",
      "epoch 1280 : 0.05884362241410444\n",
      "epoch 1320 : 0.05014391792489629\n",
      "epoch 1360 : 0.04361835738656155\n",
      "epoch 1400 : 0.03854329345292914\n",
      "epoch 1440 : 0.034484655029682024\n",
      "epoch 1480 : 0.03116724616177017\n",
      "epoch 1520 : 0.028408045961767558\n",
      "epoch 1560 : 0.026080275707001086\n",
      "epoch 1600 : 0.02409305020566546\n",
      "epoch 1640 : 0.022379313692486323\n",
      "epoch 1680 : 0.02088838623507229\n",
      "epoch 1720 : 0.019581185849515986\n",
      "epoch 1760 : 0.018427062292891483\n",
      "epoch 1800 : 0.017401634659744317\n",
      "epoch 1840 : 0.016485273901768724\n",
      "epoch 1880 : 0.0156620119640112\n",
      "epoch 1920 : 0.014918740894055755\n",
      "epoch 1960 : 0.014244614003038928\n",
      "epoch 2000 : 0.013630590985617091\n",
      "epoch 2040 : 0.013069087600804646\n",
      "epoch 2080 : 0.012553702816024791\n",
      "epoch 2120 : 0.012079003947601127\n",
      "epoch 2160 : 0.011640356008110827\n",
      "epoch 2200 : 0.011233785061958492\n",
      "epoch 2240 : 0.010855868024030147\n",
      "epoch 2280 : 0.010503643205737141\n",
      "epoch 2320 : 0.010174537269686538\n",
      "epoch 2360 : 0.00986630525535468\n",
      "epoch 2400 : 0.009576981084444772\n",
      "epoch 2440 : 0.009304836518818225\n",
      "epoch 2480 : 0.009048346972632942\n",
      "epoch 2520 : 0.008806162911360362\n",
      "epoch 2560 : 0.008577085826382634\n",
      "epoch 2600 : 0.008360047972862827\n",
      "epoch 2640 : 0.008154095217173224\n",
      "epoch 2680 : 0.007958372463256744\n",
      "epoch 2720 : 0.007772111226467273\n",
      "epoch 2760 : 0.007594619002190698\n",
      "epoch 2800 : 0.00742527014009802\n",
      "epoch 2840 : 0.007263497985352535\n",
      "epoch 2880 : 0.007108788090038334\n",
      "epoch 2920 : 0.006960672331332897\n",
      "epoch 2960 : 0.0068187238003382805\n",
      "epoch 3000 : 0.006682552347976413\n",
      "epoch 3040 : 0.006551800692760869\n",
      "epoch 3080 : 0.006426141010448603\n",
      "epoch 3120 : 0.00630527193812186\n",
      "epoch 3160 : 0.00618891593570725\n",
      "epoch 3200 : 0.006076816956558407\n",
      "epoch 3240 : 0.005968738386030588\n",
      "epoch 3280 : 0.005864461212969301\n",
      "epoch 3320 : 0.005763782404170701\n",
      "epoch 3360 : 0.0056665134561236195\n",
      "epoch 3400 : 0.005572479101983115\n",
      "epoch 3440 : 0.005481516154751895\n",
      "epoch 3480 : 0.005393472470264962\n",
      "epoch 3520 : 0.005308206015769476\n",
      "epoch 3560 : 0.005225584031775564\n",
      "epoch 3600 : 0.0051454822764617466\n",
      "epoch 3640 : 0.005067784343297088\n",
      "epoch 3680 : 0.004992381046269032\n",
      "epoch 3720 : 0.004919169855989521\n",
      "epoch 3760 : 0.004848054390052305\n",
      "epoch 3800 : 0.004778943958646685\n",
      "epoch 3840 : 0.004711753142262855\n",
      "epoch 3880 : 0.004646401407873452\n",
      "epoch 3920 : 0.004582812753491135\n",
      "epoch 3960 : 0.004520915398350569\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network.train([X_train.shape[0],8, y_train.shape[0]], iterations=4000, learning_rate=0.1, adam_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neural_network.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 5, 2, 7, 2, 1, 0, 1, 4, 0, 4, 7, 6, 7, 5, 0, 6, 5, 4, 6, 2,\n",
       "       7, 5, 5, 0, 5, 6, 1, 0, 3, 6, 7, 1, 6, 2, 3, 7, 3, 2, 1, 1, 6, 7,\n",
       "       2, 7, 4, 0, 1, 0, 3, 2, 6, 1, 6, 3, 1, 3, 7, 4, 4, 3, 5, 5, 2, 3,\n",
       "       2, 0, 1, 0, 1, 5, 3, 0, 3, 4, 4, 5, 0, 4, 4, 5, 4, 0, 1, 5, 7, 0,\n",
       "       6, 6, 3, 1, 1, 1, 3, 3, 1, 5, 6, 3, 3, 0, 3, 2, 3, 2, 2, 2, 3, 0,\n",
       "       4, 1, 2, 6, 3, 5, 3, 2, 0, 6, 4, 2, 7, 4, 4, 7, 6, 1, 1, 7, 0, 4,\n",
       "       5, 3, 3, 2, 7, 2, 0, 3, 7, 3, 0, 7, 3, 6, 2, 0, 5, 1, 0, 4, 3, 3,\n",
       "       7, 0, 1, 6, 0, 7, 7, 5, 1, 2, 4, 6, 1, 2, 1, 1, 5, 3, 6, 6, 0, 1,\n",
       "       4, 6, 4, 1, 6, 3, 2, 6, 3, 2, 7, 5, 1, 5, 4, 2, 3, 6, 1, 6, 5, 6,\n",
       "       0, 4, 4, 2, 7, 2, 4, 5, 1, 4, 4, 1, 5, 0, 2, 0, 6, 3, 7, 0, 6, 4,\n",
       "       5, 3, 1, 6, 3, 0, 5, 6, 4, 5, 3, 0, 1, 6, 2, 0, 6, 3, 7, 0, 2, 2,\n",
       "       4, 6, 0, 5, 7, 7, 0, 5, 4, 6, 5, 3, 4, 2, 4, 0, 4, 5, 3, 0, 2, 5,\n",
       "       3, 4, 5, 5, 4, 6, 0, 6, 6, 5, 1, 2, 2, 6, 1, 1, 6, 6, 7, 2, 0, 2,\n",
       "       5, 2, 4, 7, 4, 0, 4, 4, 6, 5, 0, 2, 0, 1, 2, 4, 0, 6, 6, 3, 6, 2,\n",
       "       0, 5, 1, 5, 1, 0, 4, 1, 3, 5, 2, 5, 6, 6, 6, 2, 7, 3, 0, 0, 2, 6,\n",
       "       0, 5, 5, 3, 6, 5, 0, 4, 4, 0, 2, 1, 3, 4, 1, 2, 7, 4, 0, 7, 5, 5,\n",
       "       3, 0, 3, 6, 2, 5, 4, 3, 6, 5, 2, 0, 5, 7, 5, 5, 3, 2, 5, 7, 7, 1,\n",
       "       3, 5, 5, 4, 5, 7, 6, 3, 6, 0, 3, 0, 3, 5, 3, 2, 4, 3, 1, 2, 6, 2,\n",
       "       5, 5, 2, 0, 6, 2, 0, 5, 7, 6, 1, 6, 2, 5, 0, 7, 4, 4, 6, 0, 5, 0,\n",
       "       7, 0, 2, 5, 7, 3, 0, 6, 4, 0, 7, 7, 7, 4, 3, 0, 3, 5, 0, 6, 7, 7,\n",
       "       1, 7, 2, 1, 1, 7, 3, 3, 7, 0, 4, 6, 4, 5, 6, 7, 1, 5, 5, 7, 7, 2,\n",
       "       1, 5, 5, 4, 5, 3, 3, 1, 0, 4, 6, 2, 1, 3, 5, 1, 7, 1, 2, 7, 4, 1,\n",
       "       4, 7, 4, 0, 3, 0, 2, 6, 6, 4, 7, 3, 3, 3, 4, 1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred.T, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 5, 2, 7, 2, 1, 0, 1, 4, 0, 4, 7, 6, 7, 5, 0, 6, 5, 4, 6, 2,\n",
       "       7, 5, 5, 0, 5, 6, 1, 0, 3, 6, 7, 1, 6, 2, 3, 7, 3, 2, 1, 1, 6, 7,\n",
       "       2, 7, 4, 0, 1, 0, 3, 2, 6, 1, 6, 3, 1, 3, 7, 4, 4, 3, 5, 5, 2, 3,\n",
       "       2, 0, 1, 0, 1, 5, 3, 0, 3, 4, 4, 5, 0, 4, 4, 5, 4, 0, 1, 5, 7, 0,\n",
       "       6, 6, 3, 1, 1, 1, 3, 3, 1, 5, 6, 3, 3, 0, 3, 2, 3, 2, 2, 2, 3, 0,\n",
       "       4, 1, 2, 6, 3, 5, 3, 2, 0, 6, 4, 2, 7, 4, 4, 7, 6, 1, 1, 7, 0, 4,\n",
       "       5, 3, 3, 2, 7, 2, 0, 3, 7, 3, 0, 7, 3, 6, 2, 0, 5, 1, 0, 4, 3, 3,\n",
       "       7, 0, 1, 6, 0, 7, 7, 5, 1, 2, 4, 6, 1, 2, 1, 1, 5, 3, 6, 6, 0, 1,\n",
       "       4, 6, 4, 1, 6, 3, 2, 6, 3, 2, 7, 5, 1, 5, 4, 2, 3, 6, 1, 6, 5, 6,\n",
       "       0, 4, 4, 2, 7, 2, 4, 5, 1, 4, 4, 1, 5, 0, 2, 0, 6, 3, 7, 0, 6, 4,\n",
       "       5, 3, 1, 6, 3, 0, 5, 6, 4, 5, 3, 0, 1, 6, 2, 0, 6, 3, 7, 0, 2, 2,\n",
       "       4, 6, 0, 5, 7, 7, 0, 5, 4, 6, 5, 3, 4, 2, 4, 0, 4, 5, 3, 0, 2, 5,\n",
       "       3, 4, 5, 5, 4, 6, 0, 6, 6, 5, 1, 2, 2, 6, 1, 1, 6, 6, 7, 2, 0, 2,\n",
       "       5, 2, 4, 7, 4, 0, 4, 4, 6, 5, 0, 2, 0, 1, 2, 4, 0, 6, 6, 3, 6, 2,\n",
       "       0, 5, 1, 5, 1, 0, 4, 1, 3, 5, 2, 5, 6, 6, 6, 2, 7, 3, 0, 0, 2, 6,\n",
       "       0, 5, 5, 3, 6, 5, 0, 4, 4, 0, 2, 1, 3, 4, 1, 2, 7, 4, 0, 7, 5, 5,\n",
       "       3, 0, 3, 6, 2, 5, 4, 3, 6, 5, 2, 0, 5, 7, 5, 5, 3, 2, 5, 7, 7, 1,\n",
       "       3, 5, 5, 4, 5, 7, 6, 3, 6, 0, 3, 0, 3, 5, 3, 2, 4, 3, 1, 2, 6, 2,\n",
       "       5, 5, 2, 0, 6, 2, 0, 5, 7, 6, 1, 6, 2, 5, 0, 7, 4, 4, 6, 0, 5, 0,\n",
       "       7, 0, 2, 5, 7, 3, 0, 6, 4, 0, 7, 7, 7, 4, 3, 0, 3, 5, 0, 6, 7, 7,\n",
       "       1, 7, 2, 1, 1, 7, 3, 3, 7, 0, 4, 6, 4, 5, 6, 7, 1, 5, 5, 7, 7, 2,\n",
       "       1, 5, 5, 4, 5, 3, 3, 1, 0, 4, 6, 2, 1, 3, 5, 1, 7, 1, 2, 7, 4, 1,\n",
       "       4, 7, 4, 0, 3, 0, 2, 6, 6, 4, 7, 3, 3, 3, 4, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_val.T, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_pred.T, axis = 1), np.argmax(y_val.T, axis = 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
