{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning class exercise list 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data_size, train_val_split = 0.1):\n",
    "    X = np.zeros((data_size, 3),dtype=np.float128)\n",
    "    y = np.zeros((data_size, 8),dtype=np.float128)\n",
    "    for i in range(data_size):\n",
    "        arr = np.random.randint(0, 2, 3) + np.random.uniform(-0.1,0.1, 3)\n",
    "        X[i] = np.round(arr,4)\n",
    "        y[i][int(round(arr[0]) * 4 + round(arr[1]) * 2+ round(arr[2]))] = 1\n",
    "    \n",
    "    val_split = round(data_size * (1 - train_val_split))\n",
    "\n",
    "    X_train, y_train = X[:val_split].T, y[:val_split].T\n",
    "    X_val, y_val = X[val_split:].T, y[val_split:].T\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data2(data_size, train_val_split = 0.1):\n",
    "    X = np.zeros((data_size, 1))\n",
    "    y = np.zeros((data_size, 1))\n",
    "    for i in range(data_size):\n",
    "        arr = np.random.randint(0, 2, 1) + np.random.uniform(-0.1,0.1, 1)\n",
    "        X[i] = np.round(arr,4)\n",
    "        y[i] = int(np.round(X[i]))\n",
    "    \n",
    "#     val_split = round(data_size * (1 - train_val_split))\n",
    "#     X_train, y_train = X[:val_split].T, y[:val_split].T\n",
    "#     X_val, y_val = X[val_split:].T, y[val_split:].T\n",
    "    return X.T, y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = generate_data(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(value):\n",
    "    return 1/(1 + np.exp(-value))\n",
    "\n",
    "def sigmoid_derivative(value):\n",
    "    return sigmoid(value) * (1 - sigmoid(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(value):\n",
    "    expA = np.exp(value.T - np.max(value.T, axis=1, keepdims=True))\n",
    "    return (expA / expA.sum(axis=1, keepdims=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(value):\n",
    "    return np.maximum(value, 0)\n",
    "\n",
    "def relu_derivative(value):\n",
    "    value[relu(value) <=0] = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes your class:\n",
    "            parameters : dictionary of parameters, which will store W and b through propagation.\n",
    "            cache : dictionary of cache, which will be responsible for storing A and Z during the propagation.\n",
    "            grads: dictionary of gradients, which will store all gradients computed during backprop.\n",
    "        \n",
    "        Args:\n",
    "            No arguments taken.\n",
    "        return:\n",
    "            No return.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.parameters = {}\n",
    "        self.cache = {}\n",
    "        self.grads = {}\n",
    "\n",
    "    def fit(self, X_train, y_train, hidden=relu, output=softmax):\n",
    "        \"\"\"\n",
    "        Args : \n",
    "            X_train = input data of shape (n_x, number_of_examples).\n",
    "            y_train = label vector of shape (n_y, number_of_examples).\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.m = X_train.shape[1]\n",
    "        self.hidden = hidden # function passed as argument to be used on hidden layers\n",
    "        self.output = output # function passed as argument to be used on output layers\n",
    "\n",
    "    def initialize_parameters(self, dims):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dims = dimensions of the network.\n",
    "            \n",
    "            Example:\n",
    "                dims = [3,3,8]\n",
    "                \n",
    "                A network with input size = 3, hidden layer = 3 and output layer = 8.\n",
    "                \n",
    "                The first dimension on the list must always be the length of each example.\n",
    "                The last dimension on the list must always be the length of each output example.\n",
    "                \n",
    "                In a case where X_train shape = (3, 4500) and y_train shape = (8, 4500), 4500 in\n",
    "                each shape represents the number of examples.\n",
    "                \n",
    "                dims = [3, 8]\n",
    "        Return:\n",
    "            parameters : a dictionary containing all weights and biases intialized\n",
    "                \n",
    "        \"\"\"\n",
    "        self.L = len(dims)\n",
    "        for l in range(1, self.L):\n",
    "            self.parameters[\"W\" + str(l)] = np.random.randn(dims[l], dims[l-1])\n",
    "            self.parameters[\"b\" + str(l)] = np.zeros((dims[l], 1))\n",
    "        return self.parameters\n",
    "    \n",
    "    def propagate(self, X):\n",
    "        \"\"\"\n",
    "        Does the forward propagation of the network\n",
    "        \"\"\"\n",
    "        A_prev = X\n",
    "        self.cache[f\"A{0}\"] = A_prev\n",
    "        for l in range(1, self.L):\n",
    "            \n",
    "            Z = np.dot(self.parameters[f\"W{l}\"], A_prev) + self.parameters[f\"b{l}\"]\n",
    "\n",
    "            if l == self.L - 1:\n",
    "                A = self.output(Z)\n",
    "            else:\n",
    "                A = self.hidden(Z)\n",
    "\n",
    "            self.cache[f\"Z{l}\"] = Z\n",
    "            self.cache[f\"A{l}\"] = A\n",
    "            \n",
    "            A_prev = A\n",
    "        \n",
    "        self.y_hat = A\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the value using the propagate function\n",
    "        \n",
    "        Args:\n",
    "            X : data to be used on prediction\n",
    "        Return:\n",
    "            y_hat : data predicted\n",
    "        \"\"\"\n",
    "        self.propagate(X)\n",
    "        return self.y_hat\n",
    "    \n",
    "    def error(self):\n",
    "        pred = self.y_hat.T\n",
    "        real = self.y_train.T\n",
    "        n_samples = real.shape[0]\n",
    "        logp = - np.log(pred[np.arange(n_samples), real.argmax(axis=1)])\n",
    "        loss = np.sum(logp)/(n_samples)\n",
    "        return loss\n",
    "\n",
    "    def cross_entropy(self):\n",
    "        res = self.y_hat - self.y_train\n",
    "        return res\n",
    "\n",
    "    def compute_grads(self):\n",
    "        cross_entropy_value = self.cross_entropy()\n",
    "        \n",
    "        dZ = cross_entropy_value\n",
    "\n",
    "        self.grads[f\"dW{self.L - 1}\"] = 1/self.m * (np.dot(dZ, self.cache[f\"A{self.L - 2}\"].T))\n",
    "        self.grads[f\"db{self.L - 1}\"] = 1/self.m * np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "        for l in reversed(range(1, self.L - 1)):\n",
    "            self.grads[f\"dA_prev{l}\"] = np.dot(self.parameters[f\"W{l + 1}\"].T,dZ)\n",
    "            dZ = self.grads[f\"dA_prev{l}\"] * relu_derivative(self.cache[f\"Z{l}\"])\n",
    "            self.grads[f\"dW{l}\"] = 1/self.m * (np.dot(dZ, self.cache[f\"A{l - 1}\"].T))\n",
    "            self.grads[f\"db{l}\"] = 1/self.m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    \n",
    "    def backprop(self, learning_rate = 0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "        for l in reversed(range(1, self.L)):\n",
    "            #print(l)\n",
    "            self.parameters[\"W\"+str(l)] -= self.learning_rate * (self.grads[f\"dW{l}\"])\n",
    "            self.parameters[\"b\"+str(l)] -= self.learning_rate * (self.grads[f\"db{l}\"])\n",
    "\n",
    "    def compute_cost(self):\n",
    "        logprods = np.dot(self.y_train, np.log(self.y_hat).T) + np.dot((1-self.y_train), np.log(1- self.y_hat).T)\n",
    "        cost = -1/self.m*np.sum(logprods)\n",
    "        \n",
    "        return np.sum(self.loss)/self.m\n",
    "\n",
    "    def train(self, dims, learning_rate = 0.01, iterations = 1000):\n",
    "        printing_interval = round(iterations * 0.01)\n",
    "        self.initialize_parameters(dims)\n",
    "        costs = []\n",
    "        for i in range(iterations):\n",
    "            self.propagate(self.X_train)\n",
    "            loss = self.error()\n",
    "            if i % printing_interval == 0:\n",
    "                print(f\"epoch {i} : {loss}\")\n",
    "            costs.append(loss)\n",
    "            self.compute_grads()\n",
    "            self.backprop(learning_rate = learning_rate)\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per hundreds)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val , y_train, y_val = generate_data(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 5.409663895024497\n",
      "epoch 50 : 1.7647741502107657\n",
      "epoch 100 : 1.4084206010963762\n",
      "epoch 150 : 1.262580037681157\n",
      "epoch 200 : 1.148467679422792\n",
      "epoch 250 : 0.8689795546763687\n",
      "epoch 300 : 0.7613747982964134\n",
      "epoch 350 : 0.8103147143737719\n",
      "epoch 400 : 0.5382307816686325\n",
      "epoch 450 : 0.4744851095039884\n",
      "epoch 500 : 0.37326934338671713\n",
      "epoch 550 : 0.25797460717735354\n",
      "epoch 600 : 3.2408520700512815\n",
      "epoch 650 : 1.2519175995536729\n",
      "epoch 700 : 1.1243481349584465\n",
      "epoch 750 : 1.038295111338606\n",
      "epoch 800 : 0.9797057287973799\n",
      "epoch 850 : 0.9403633977988954\n",
      "epoch 900 : 0.9093414971448963\n",
      "epoch 950 : 0.8814512223023158\n",
      "epoch 1000 : 0.8551927538998849\n",
      "epoch 1050 : 0.8302075974585025\n",
      "epoch 1100 : 0.8064778567448194\n",
      "epoch 1150 : 0.7840413288097615\n",
      "epoch 1200 : 0.7630685898000124\n",
      "epoch 1250 : 0.7437360291596895\n",
      "epoch 1300 : 0.7260036993419747\n",
      "epoch 1350 : 0.709685307426376\n",
      "epoch 1400 : 0.6943634794536958\n",
      "epoch 1450 : 0.6784453092469277\n",
      "epoch 1500 : 0.6385968049551156\n",
      "epoch 1550 : 0.583925099725276\n",
      "epoch 1600 : 0.5481175359562587\n",
      "epoch 1650 : 0.5179326206344109\n",
      "epoch 1700 : 0.488564166277315\n",
      "epoch 1750 : 0.4591563004486016\n",
      "epoch 1800 : 0.431432677024017\n",
      "epoch 1850 : 0.40823018309164394\n",
      "epoch 1900 : 0.38913914711042175\n",
      "epoch 1950 : 0.37211332001631703\n",
      "epoch 2000 : 0.3566151622246628\n",
      "epoch 2050 : 0.3425558759799704\n",
      "epoch 2100 : 0.32969657787027584\n",
      "epoch 2150 : 0.3176963523169608\n",
      "epoch 2200 : 0.3062755640348345\n",
      "epoch 2250 : 0.29518487578524943\n",
      "epoch 2300 : 0.28426369620971975\n",
      "epoch 2350 : 0.2734034947249407\n",
      "epoch 2400 : 0.26255797639082123\n",
      "epoch 2450 : 0.2516899911951751\n",
      "epoch 2500 : 0.2407609217429423\n",
      "epoch 2550 : 0.22974686892400392\n",
      "epoch 2600 : 0.21867048892999583\n",
      "epoch 2650 : 0.20757310160173273\n",
      "epoch 2700 : 0.19652184996055266\n",
      "epoch 2750 : 0.18559487299751365\n",
      "epoch 2800 : 0.1748845684660643\n",
      "epoch 2850 : 0.1645051147725524\n",
      "epoch 2900 : 0.1545731503727399\n",
      "epoch 2950 : 0.14522965691098788\n",
      "epoch 3000 : 0.1366018991350292\n",
      "epoch 3050 : 0.128936852685553\n",
      "epoch 3100 : 0.1224882237533673\n",
      "epoch 3150 : 0.11699512594972244\n",
      "epoch 3200 : 0.11180034028131061\n",
      "epoch 3250 : 0.10681308600901668\n",
      "epoch 3300 : 0.10216013478002749\n",
      "epoch 3350 : 0.09790370283352458\n",
      "epoch 3400 : 0.09403504442063304\n",
      "epoch 3450 : 0.09051902950933731\n",
      "epoch 3500 : 0.08731275069575122\n",
      "epoch 3550 : 0.0843709004589705\n",
      "epoch 3600 : 0.08165036392862911\n",
      "epoch 3650 : 0.07911801565823202\n",
      "epoch 3700 : 0.07674593432194483\n",
      "epoch 3750 : 0.07451471826532136\n",
      "epoch 3800 : 0.0724084027517932\n",
      "epoch 3850 : 0.07041290367610314\n",
      "epoch 3900 : 0.06851702353261799\n",
      "epoch 3950 : 0.06671464063819726\n",
      "epoch 4000 : 0.06499977698200186\n",
      "epoch 4050 : 0.06336432590868404\n",
      "epoch 4100 : 0.06180329160287681\n",
      "epoch 4150 : 0.060311395928296915\n",
      "epoch 4200 : 0.05888338064666651\n",
      "epoch 4250 : 0.05751620261100905\n",
      "epoch 4300 : 0.056203773837325416\n",
      "epoch 4350 : 0.05494468790337175\n",
      "epoch 4400 : 0.05373392107917679\n",
      "epoch 4450 : 0.05257056030787057\n",
      "epoch 4500 : 0.051453080592553706\n",
      "epoch 4550 : 0.05037723691057355\n",
      "epoch 4600 : 0.049340563266283305\n",
      "epoch 4650 : 0.04834105923902442\n",
      "epoch 4700 : 0.04737681471732409\n",
      "epoch 4750 : 0.046446036144926116\n",
      "epoch 4800 : 0.04554587939965865\n",
      "epoch 4850 : 0.04467515619805594\n",
      "epoch 4900 : 0.04383284646255988\n",
      "epoch 4950 : 0.04301784017332524\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlp.train([X_train.shape[0], 10, 10, y_train.shape[0]], iterations=5000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 5000)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 0, ..., 2, 7, 4])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred.T, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 0, ..., 2, 7, 4])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_val.T, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## opa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_pred.T, axis = 1), np.argmax(y_val.T, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
