{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning class exercise list 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data_size, train_val_split = 0.1):\n",
    "    X = np.zeros((data_size, 3),dtype=np.float128)\n",
    "    y = np.zeros((data_size, 8),dtype=np.float128)\n",
    "    for i in range(data_size):\n",
    "        arr = np.random.randint(0, 2, 3) + np.random.uniform(-0.1,0.1, 3)\n",
    "        X[i] = np.round(arr,4)\n",
    "        y[i][int(round(arr[0]) * 4 + round(arr[1]) * 2+ round(arr[2]))] = 1\n",
    "    \n",
    "    val_split = round(data_size * (1 - train_val_split))\n",
    "\n",
    "    X_train, y_train = X[:val_split].T, y[:val_split].T\n",
    "    X_val, y_val = X[val_split:].T, y[val_split:].T\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(value):\n",
    "    return value\n",
    "\n",
    "def linear_derivative(value):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(value):\n",
    "    return 1/(1 + np.exp(-value))\n",
    "\n",
    "def sigmoid_derivative(value):\n",
    "    return sigmoid(value) * (1 - sigmoid(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(value):\n",
    "    expA = np.exp(value.T - np.max(value.T, axis=1, keepdims=True))\n",
    "    return (expA / expA.sum(axis=1, keepdims=True)).T\n",
    "\n",
    "def softmax_derivative(value):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(value):\n",
    "    return np.maximum(value, 0)\n",
    "\n",
    "def relu_derivative(value):\n",
    "    value[relu(value) <=0] = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially Weighted Average\n",
    "$$\n",
    "V_{10} = \\frac{0.1\\theta_{10} + 0.9\\cdot0.1\\theta_{9} + 0.9^2\\cdot0.1\\theta_{8} + \\cdots + 0.9^8\\cdot0.1\\theta_{2} + 0.9^9\\cdot0.1\\theta_{1}}{10}\n",
    "$$\n",
    "* This is how we usually compute an average. Although, having to keep all theses values in memory is costly. One alternative way would be to compute $V_{10}$ taking into account only $V_9$ and $\\theta_{10}$.\n",
    "$$\n",
    "V_{10} = \\frac{9}{10}V_9 + \\frac{1}{10}\\theta_{10}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which can be modelled as:\n",
    "$$\n",
    "V_t = \\beta V_{t-1} + (1 - \\beta) \\theta_t\n",
    "$$\n",
    "Where $\\beta$ is calculled as $\\frac{t -1}{t}$  \n",
    "the time window can be calculed through having the value of $\\beta$ as $\\frac{1}{1 - \\beta}$ days/windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In early training, we have to do a bias correction in this averaging, in order to compensate the lack of data in previous time steps inserted on the time window. At time step 0, if working with a 0.9 $\\beta$, we will have a \n",
    "time window of 10, but our estimates will be biased and far from the real cause it will lack more terms that should make a parte of the exponentially weighted average. In order to fix this, we divide the $V$ value calculated by (1 - $\\beta^t$) which will \"normalize\" the initial values and wont affect the values the other ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "V_t = \\frac{V_t}{1 - \\beta^t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes your class:\n",
    "            parameters : dictionary of parameters, which will store W and b through propagation.\n",
    "            cache : dictionary of cache, which will be responsible for storing A and Z during the propagation.\n",
    "            grads: dictionary of gradients, which will store all gradients computed during backprop.\n",
    "            v : dictionary with momentum ewa estimates\n",
    "            s : dictionary with RMSprop ewa estimates\n",
    "        Args:\n",
    "            No arguments taken.\n",
    "        return:\n",
    "            No return.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.parameters = {}\n",
    "        self.cache = {}\n",
    "        self.grads = {}\n",
    "        self.v = {}\n",
    "        self.s = {}\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val, y_val, hidden=\"relu\", output=\"softmax\"):\n",
    "        \"\"\"\n",
    "        Args : \n",
    "            X_train = input data of shape (n_x, number_of_examples).\n",
    "            y_train = label vector of shape (n_y, number_of_examples).\n",
    "            X_val = input data of shape (n_x, number_of_examples_validation).\n",
    "            y_val = label vector of shape (n_y, number_of_examples_validation).\n",
    "            hidden : passed as argument the function used on the hidden layers\n",
    "            output : function used on output layer\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.m = X_train.shape[1]\n",
    "\n",
    "        if output == \"sigmoid\":\n",
    "            self.output = sigmoid # function passed as argument to be used on output layers\n",
    "            self.output_derivative = sigmoid_derivative\n",
    "        elif output == \"softmax\":\n",
    "            self.output = softmax\n",
    "            self.output_derivative = softmax_derivative\n",
    "        else:\n",
    "            print(\"output activation not recognized\")\n",
    "            return -1\n",
    "        \n",
    "        if hidden == \"relu\":\n",
    "            self.hidden = relu\n",
    "            self.hidden_derivative = relu_derivative\n",
    "        elif hidden == \"sigmoid\":\n",
    "            self.hidden = sigmoid\n",
    "            self.hidden_derivative = sigmoid_derivative\n",
    "        else:\n",
    "            print(\"hidden activation not recognized\")\n",
    "            return -1\n",
    "    \n",
    "    def initialize_parameters(self, dims, adam_optimizer=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dims = dimensions of the network.\n",
    "            \n",
    "            Example:\n",
    "                dims = [3,3,8]\n",
    "                \n",
    "                A network with input size = 3, hidden layer = 3 and output layer = 8.\n",
    "                \n",
    "                The first dimension on the list must always be the length of each example.\n",
    "                The last dimension on the list must always be the length of each output example.\n",
    "                \n",
    "                In a case where X_train shape = (3, 4500) and y_train shape = (8, 4500), 4500 in\n",
    "                each shape represents the number of examples.\n",
    "                \n",
    "                dims = [3, 8]\n",
    "        Return:\n",
    "            parameters : a dictionary containing all weights and biases intialized\n",
    "                \n",
    "        \"\"\"\n",
    "        self.L = len(dims)\n",
    "        for l in range(1, self.L):\n",
    "            self.parameters[\"W\" + str(l)] = np.random.randn(dims[l], dims[l-1]) * 0.01\n",
    "            self.parameters[\"b\" + str(l)] = np.zeros((dims[l], 1))\n",
    "            if adam_optimizer:\n",
    "                self.v[\"VdW\" + str(l)] = np.zeros((dims[l], dims[l-1]))\n",
    "                self.v[\"Vdb\" + str(l)] = np.zeros((dims[l], 1))\n",
    "                self.s[\"SdW\" + str(l)] = np.zeros((dims[l], dims[l-1]))\n",
    "                self.s[\"Sdb\" + str(l)] = np.zeros((dims[l], 1))\n",
    "        return self.parameters\n",
    "    \n",
    "    def propagate(self, X):\n",
    "        \"\"\"\n",
    "        Does the forward propagation of the network\n",
    "        \"\"\"\n",
    "        A_prev = X\n",
    "        self.cache[f\"A{0}\"] = A_prev\n",
    "        for l in range(1, self.L):\n",
    "            \n",
    "            Z = np.dot(self.parameters[f\"W{l}\"], A_prev) + self.parameters[f\"b{l}\"]\n",
    "\n",
    "            if l == self.L - 1:\n",
    "                A = self.output(Z)\n",
    "            else:\n",
    "                A = self.hidden(Z)\n",
    "\n",
    "            self.cache[f\"Z{l}\"] = Z\n",
    "            self.cache[f\"A{l}\"] = A\n",
    "            \n",
    "            A_prev = A\n",
    "        \n",
    "        self.y_hat = A\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the value\n",
    "        \n",
    "        Args:\n",
    "            X : data to be used on prediction\n",
    "        Return:\n",
    "            y_hat : data predicted\n",
    "        \"\"\"\n",
    "        A_prev = X\n",
    "\n",
    "        for l in range(1, self.L):\n",
    "            \n",
    "            Z = np.dot(self.parameters[f\"W{l}\"], A_prev) + self.parameters[f\"b{l}\"]\n",
    "\n",
    "            if l == self.L - 1:\n",
    "                A = self.output(Z)\n",
    "            else:\n",
    "                A = self.hidden(Z)\n",
    "            \n",
    "            A_prev = A\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def compute_cost(self, pred, real):\n",
    "        pred = pred.T\n",
    "        real = real.T\n",
    "        n_samples = real.shape[0]\n",
    "        logp = - np.log(pred[np.arange(n_samples), real.argmax(axis=1)])\n",
    "        cost = np.sum(logp)/(n_samples)\n",
    "        return cost\n",
    "\n",
    "    def loss(self):\n",
    "        res = self.y_hat - self.y_train\n",
    "        return res\n",
    "\n",
    "    def backprop(self):\n",
    "        dA = self.loss()\n",
    "        \n",
    "        dZ = dA * self.output_derivative(self.cache[f\"Z{self.L - 1}\"])\n",
    "        \n",
    "        self.grads[f\"dW{self.L - 1}\"] = 1/self.m * (np.dot(dZ, self.cache[f\"A{self.L - 2}\"].T))\n",
    "        self.grads[f\"db{self.L - 1}\"] = 1/self.m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        \n",
    "        \n",
    "        for l in reversed(range(1, self.L - 1)):\n",
    "            self.grads[f\"dA_prev{l}\"] = np.dot(self.parameters[f\"W{l + 1}\"].T,dZ)\n",
    "            dZ = self.grads[f\"dA_prev{l}\"] * self.hidden_derivative(self.cache[f\"Z{l}\"])\n",
    "            self.grads[f\"dW{l}\"] = 1/self.m * (np.dot(dZ, self.cache[f\"A{l - 1}\"].T))\n",
    "            self.grads[f\"db{l}\"] = 1/self.m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    \n",
    "    def update_grads_adam(self, t, learning_rate = 0.01, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8):\n",
    "        \"\"\"\n",
    "        ADAM -> Adaptive Moment estimation\n",
    "        Args:\n",
    "            t : epoch number\n",
    "            learning_rate : learning rate chosed to upgrade weights\n",
    "            beta1 : exponentially weighted average used on v (momentum), beta1 = 0.9 (recommended on paper) is approx 10 days ewa\n",
    "            beta1 : exponentially weighted average used on s (RMSprop), beta2 = 0.999 (recommended on paper)\n",
    "            epsilon : term to prevent division by zero\n",
    "        \"\"\"\n",
    "        \n",
    "        v_biasCorrected = {}\n",
    "        s_biasCorrected = {}\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        for l in reversed(range(1, self.L)):\n",
    "            # moving average of the gradients\n",
    "            self.v[f\"VdW{l}\"] = beta1 * self.v[f\"VdW{l}\"] + (1 - beta1)* self.grads[f\"dW{l}\"]\n",
    "            self.v[f\"Vdb{l}\"] = beta1 * self.v[f\"Vdb{l}\"] + (1 - beta1)* self.grads[f\"db{l}\"]\n",
    "\n",
    "            v_biasCorrected[f\"VdW{l}\"] = self.v[f\"VdW{l}\"]/(1 - beta1 ** t) # bias correction to the first updates\n",
    "            v_biasCorrected[f\"Vdb{l}\"] = self.v[f\"Vdb{l}\"]/(1 - beta1 ** t) # bias correction\n",
    "\n",
    "            self.s[f\"SdW{l}\"] = beta2 * self.s[f\"SdW{l}\"] + (1 - beta2) * np.square(self.grads[f\"dW{l}\"])\n",
    "            self.s[f\"Sdb{l}\"] = beta2 * self.s[f\"Sdb{l}\"] + (1 - beta2) * np.square(self.grads[f\"db{l}\"])\n",
    "                                                                                             \n",
    "            s_biasCorrected[f\"SdW{l}\"] = self.s[f\"SdW{l}\"]/(1 - beta2 ** t) # bias correction to the first updates\n",
    "            s_biasCorrected[f\"Sdb{l}\"] = self.s[f\"Sdb{l}\"]/(1 - beta2 ** t) # bias correction\n",
    "            \n",
    "            self.parameters[f\"W{l}\"] -= self.learning_rate * (v_biasCorrected[f\"VdW{l}\"])/(np.sqrt(s_biasCorrected[f\"SdW{l}\"]) + epsilon)\n",
    "            self.parameters[f\"b{l}\"] -= self.learning_rate * (v_biasCorrected[f\"Vdb{l}\"])/(np.sqrt(s_biasCorrected[f\"Sdb{l}\"]) + epsilon)\n",
    "                                                                                               \n",
    "    def update_grads_gd(self, learning_rate = 0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            learning_rate : learning rate chosed to upgrade weights\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        for l in reversed(range(1, self.L)):\n",
    "            self.parameters[f\"W{l}\"] -= self.learning_rate * (self.grads[f\"dW{l}\"])\n",
    "            self.parameters[f\"b{l}\"] -= self.learning_rate * (self.grads[f\"db{l}\"])\n",
    "\n",
    "    def train(self, dims, learning_rate = 0.01, iterations = 1000, adam_optimizer=False):\n",
    "        #ATE AQUI TA SAFE PORRA\n",
    "        if iterations > 100:\n",
    "            printing_interval = round(iterations * 0.01)\n",
    "        else:\n",
    "            printing_interval = 1\n",
    "        self.initialize_parameters(dims, adam_optimizer=adam_optimizer)\n",
    "        \n",
    "        costs = []\n",
    "        val_costs = []\n",
    "\n",
    "        for i in range(iterations):\n",
    "            self.propagate(self.X_train)\n",
    "            cost = self.compute_cost(self.y_hat, self.y_train)\n",
    "            \n",
    "            y_hat_val = self.predict(self.X_val)\n",
    "            val_cost = self.compute_cost(y_hat_val, self.y_val)\n",
    "            val_costs.append(val_cost)\n",
    "            \n",
    "            if i % printing_interval == 0:\n",
    "                print(f\"EPOCH {i} Train cost : {np.round(cost,8)} | val cost : {np.round(val_cost,8)}\")\n",
    "                \n",
    "            costs.append(cost)\n",
    "            \n",
    "            self.backprop()\n",
    "            \n",
    "            if adam_optimizer:\n",
    "                self.update_grads_adam(t=i+1, learning_rate=learning_rate)\n",
    "            else:\n",
    "                self.update_grads_gd(learning_rate = learning_rate)\n",
    "\n",
    "        plt.plot(np.squeeze(costs), color=\"blue\", label=\"train\")\n",
    "        plt.plot(np.squeeze(val_costs), color=\"orange\", label=\"val\")\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per hundreds)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val , y_train, y_val = generate_data(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = DNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 Train cost : 2.08622077 | val cost : 2.0866424\n",
      "EPOCH 4 Train cost : 1.56366116 | val cost : 1.56542115\n",
      "EPOCH 8 Train cost : 1.16732541 | val cost : 1.16679957\n",
      "EPOCH 12 Train cost : 0.874154 | val cost : 0.87608517\n",
      "EPOCH 16 Train cost : 0.66157554 | val cost : 0.66378149\n",
      "EPOCH 20 Train cost : 0.50781056 | val cost : 0.50876147\n",
      "EPOCH 24 Train cost : 0.3976516 | val cost : 0.39841655\n",
      "EPOCH 28 Train cost : 0.31929934 | val cost : 0.32012444\n",
      "EPOCH 32 Train cost : 0.26259699 | val cost : 0.26302058\n",
      "EPOCH 36 Train cost : 0.22087084 | val cost : 0.22103259\n",
      "EPOCH 40 Train cost : 0.18934627 | val cost : 0.18959484\n",
      "EPOCH 44 Train cost : 0.16512885 | val cost : 0.1654246\n",
      "EPOCH 48 Train cost : 0.14618925 | val cost : 0.14636901\n",
      "EPOCH 52 Train cost : 0.13108554 | val cost : 0.13115541\n",
      "EPOCH 56 Train cost : 0.11880711 | val cost : 0.11886533\n",
      "EPOCH 60 Train cost : 0.10863453 | val cost : 0.10872107\n",
      "EPOCH 64 Train cost : 0.10006159 | val cost : 0.10014691\n",
      "EPOCH 68 Train cost : 0.09273183 | val cost : 0.09278571\n",
      "EPOCH 72 Train cost : 0.08638503 | val cost : 0.08641207\n",
      "EPOCH 76 Train cost : 0.08082706 | val cost : 0.08084653\n",
      "EPOCH 80 Train cost : 0.07591253 | val cost : 0.07593138\n",
      "EPOCH 84 Train cost : 0.07152888 | val cost : 0.07154245\n",
      "EPOCH 88 Train cost : 0.06758939 | val cost : 0.06759542\n",
      "EPOCH 92 Train cost : 0.06402636 | val cost : 0.06402853\n",
      "EPOCH 96 Train cost : 0.06078572 | val cost : 0.06078742\n",
      "EPOCH 100 Train cost : 0.05782415 | val cost : 0.05782478\n",
      "EPOCH 104 Train cost : 0.05510626 | val cost : 0.05510361\n",
      "EPOCH 108 Train cost : 0.05260274 | val cost : 0.05259626\n",
      "EPOCH 112 Train cost : 0.05028906 | val cost : 0.05028025\n",
      "EPOCH 116 Train cost : 0.04814448 | val cost : 0.0481352\n",
      "EPOCH 120 Train cost : 0.04615132 | val cost : 0.04614232\n",
      "EPOCH 124 Train cost : 0.04429439 | val cost : 0.04428518\n",
      "EPOCH 128 Train cost : 0.04256051 | val cost : 0.04255027\n",
      "EPOCH 132 Train cost : 0.0409382 | val cost : 0.04092663\n",
      "EPOCH 136 Train cost : 0.03941739 | val cost : 0.03940485\n",
      "EPOCH 140 Train cost : 0.03798921 | val cost : 0.03797628\n",
      "EPOCH 144 Train cost : 0.03664577 | val cost : 0.03663279\n",
      "EPOCH 148 Train cost : 0.03538008 | val cost : 0.03536705\n",
      "EPOCH 152 Train cost : 0.03418589 | val cost : 0.03417265\n",
      "EPOCH 156 Train cost : 0.03305758 | val cost : 0.03304407\n",
      "EPOCH 160 Train cost : 0.03199011 | val cost : 0.03197638\n",
      "EPOCH 164 Train cost : 0.03097894 | val cost : 0.0309651\n",
      "EPOCH 168 Train cost : 0.03001996 | val cost : 0.03000608\n",
      "EPOCH 172 Train cost : 0.02910942 | val cost : 0.02909555\n",
      "EPOCH 176 Train cost : 0.02824395 | val cost : 0.02823009\n",
      "EPOCH 180 Train cost : 0.02742046 | val cost : 0.02740662\n",
      "EPOCH 184 Train cost : 0.02663612 | val cost : 0.02662231\n",
      "EPOCH 188 Train cost : 0.02588837 | val cost : 0.02587461\n",
      "EPOCH 192 Train cost : 0.02517484 | val cost : 0.02516116\n",
      "EPOCH 196 Train cost : 0.02449337 | val cost : 0.02447978\n",
      "EPOCH 200 Train cost : 0.02384196 | val cost : 0.02382846\n",
      "EPOCH 204 Train cost : 0.02321877 | val cost : 0.02320538\n",
      "EPOCH 208 Train cost : 0.02262212 | val cost : 0.02260884\n",
      "EPOCH 212 Train cost : 0.02205044 | val cost : 0.02203728\n",
      "EPOCH 216 Train cost : 0.02150229 | val cost : 0.02148925\n",
      "EPOCH 220 Train cost : 0.02097632 | val cost : 0.02096341\n",
      "EPOCH 224 Train cost : 0.02047129 | val cost : 0.02045853\n",
      "EPOCH 228 Train cost : 0.01998606 | val cost : 0.01997343\n",
      "EPOCH 232 Train cost : 0.01951953 | val cost : 0.01950704\n",
      "EPOCH 236 Train cost : 0.01907073 | val cost : 0.01905838\n",
      "EPOCH 240 Train cost : 0.0186387 | val cost : 0.0186265\n",
      "EPOCH 244 Train cost : 0.0182226 | val cost : 0.01821054\n",
      "EPOCH 248 Train cost : 0.01782159 | val cost : 0.01780968\n",
      "EPOCH 252 Train cost : 0.01743493 | val cost : 0.01742317\n",
      "EPOCH 256 Train cost : 0.01706191 | val cost : 0.01705029\n",
      "EPOCH 260 Train cost : 0.01670185 | val cost : 0.01669038\n",
      "EPOCH 264 Train cost : 0.01635414 | val cost : 0.01634281\n",
      "EPOCH 268 Train cost : 0.01601818 | val cost : 0.016007\n",
      "EPOCH 272 Train cost : 0.01569343 | val cost : 0.0156824\n",
      "EPOCH 276 Train cost : 0.01537937 | val cost : 0.01536848\n",
      "EPOCH 280 Train cost : 0.0150755 | val cost : 0.01506476\n",
      "EPOCH 284 Train cost : 0.01478139 | val cost : 0.01477078\n",
      "EPOCH 288 Train cost : 0.01449658 | val cost : 0.01448612\n",
      "EPOCH 292 Train cost : 0.01422067 | val cost : 0.01421035\n",
      "EPOCH 296 Train cost : 0.01395327 | val cost : 0.01394309\n",
      "EPOCH 300 Train cost : 0.01369403 | val cost : 0.01368399\n",
      "EPOCH 304 Train cost : 0.01344259 | val cost : 0.01343269\n",
      "EPOCH 308 Train cost : 0.01319864 | val cost : 0.01318886\n",
      "EPOCH 312 Train cost : 0.01296185 | val cost : 0.01295221\n",
      "EPOCH 316 Train cost : 0.01273195 | val cost : 0.01272244\n",
      "EPOCH 320 Train cost : 0.01250865 | val cost : 0.01249927\n",
      "EPOCH 324 Train cost : 0.01229169 | val cost : 0.01228244\n",
      "EPOCH 328 Train cost : 0.01208082 | val cost : 0.01207169\n",
      "EPOCH 332 Train cost : 0.0118758 | val cost : 0.0118668\n",
      "EPOCH 336 Train cost : 0.01167641 | val cost : 0.01166753\n",
      "EPOCH 340 Train cost : 0.01148244 | val cost : 0.01147368\n",
      "EPOCH 344 Train cost : 0.01129367 | val cost : 0.01128503\n",
      "EPOCH 348 Train cost : 0.01110992 | val cost : 0.0111014\n",
      "EPOCH 352 Train cost : 0.010931 | val cost : 0.01092259\n",
      "EPOCH 356 Train cost : 0.01075673 | val cost : 0.01074844\n",
      "EPOCH 360 Train cost : 0.01058696 | val cost : 0.01057877\n",
      "EPOCH 364 Train cost : 0.0104215 | val cost : 0.01041343\n",
      "EPOCH 368 Train cost : 0.01026023 | val cost : 0.01025226\n",
      "EPOCH 372 Train cost : 0.01010298 | val cost : 0.01009512\n",
      "EPOCH 376 Train cost : 0.00994961 | val cost : 0.00994186\n",
      "EPOCH 380 Train cost : 0.0098 | val cost : 0.00979236\n",
      "EPOCH 384 Train cost : 0.00965402 | val cost : 0.00964648\n",
      "EPOCH 388 Train cost : 0.00951155 | val cost : 0.00950411\n",
      "EPOCH 392 Train cost : 0.00937246 | val cost : 0.00936512\n",
      "EPOCH 396 Train cost : 0.00923665 | val cost : 0.00922941\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network.train([X_train.shape[0], y_train.shape[0]], iterations=400, learning_rate=0.1, adam_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 Train cost : 2.07943347 | val cost : 2.07942589\n",
      "EPOCH 40 Train cost : 2.07905611 | val cost : 2.07993412\n",
      "EPOCH 80 Train cost : 2.0788628 | val cost : 2.08027702\n",
      "EPOCH 120 Train cost : 2.07872927 | val cost : 2.08046905\n",
      "EPOCH 160 Train cost : 2.07860716 | val cost : 2.0805455\n",
      "EPOCH 200 Train cost : 2.07847298 | val cost : 2.08053392\n",
      "EPOCH 240 Train cost : 2.07830851 | val cost : 2.08044731\n",
      "EPOCH 280 Train cost : 2.07809266 | val cost : 2.08028374\n",
      "EPOCH 320 Train cost : 2.07780289 | val cost : 2.08003061\n",
      "EPOCH 360 Train cost : 2.07740374 | val cost : 2.07966574\n",
      "EPOCH 400 Train cost : 2.07680102 | val cost : 2.07910175\n",
      "EPOCH 440 Train cost : 2.07580075 | val cost : 2.0781577\n",
      "EPOCH 480 Train cost : 2.07395967 | val cost : 2.07641608\n",
      "EPOCH 520 Train cost : 2.07009349 | val cost : 2.07275808\n",
      "EPOCH 560 Train cost : 2.06053455 | val cost : 2.06372164\n",
      "EPOCH 600 Train cost : 2.03312523 | val cost : 2.03785794\n",
      "EPOCH 640 Train cost : 1.96734381 | val cost : 1.97576498\n",
      "EPOCH 680 Train cost : 1.87841258 | val cost : 1.88912424\n",
      "EPOCH 720 Train cost : 1.78651648 | val cost : 1.79738182\n",
      "EPOCH 760 Train cost : 1.70245279 | val cost : 1.71339212\n",
      "EPOCH 800 Train cost : 1.62796608 | val cost : 1.63911826\n",
      "EPOCH 840 Train cost : 1.56131422 | val cost : 1.57276463\n",
      "EPOCH 880 Train cost : 1.49547257 | val cost : 1.50747944\n",
      "EPOCH 920 Train cost : 1.40291812 | val cost : 1.41665395\n",
      "EPOCH 960 Train cost : 1.18771008 | val cost : 1.20584273\n",
      "EPOCH 1000 Train cost : 0.9001527 | val cost : 0.91882302\n",
      "EPOCH 1040 Train cost : 0.73051213 | val cost : 0.74698941\n",
      "EPOCH 1080 Train cost : 0.62933223 | val cost : 0.64397141\n",
      "EPOCH 1120 Train cost : 0.58830994 | val cost : 0.59585399\n",
      "EPOCH 1160 Train cost : 0.57920541 | val cost : 0.58852182\n",
      "EPOCH 1200 Train cost : 0.52885664 | val cost : 0.53584431\n",
      "EPOCH 1240 Train cost : 0.47304312 | val cost : 0.47680688\n",
      "EPOCH 1280 Train cost : 0.41618526 | val cost : 0.41678551\n",
      "EPOCH 1320 Train cost : 0.36900628 | val cost : 0.36565442\n",
      "EPOCH 1360 Train cost : 0.32607422 | val cost : 0.32074443\n",
      "EPOCH 1400 Train cost : 0.29045297 | val cost : 0.2861894\n",
      "EPOCH 1440 Train cost : 0.25302288 | val cost : 0.2509317\n",
      "EPOCH 1480 Train cost : 0.19915869 | val cost : 0.19657586\n",
      "EPOCH 1520 Train cost : 0.14781857 | val cost : 0.14785231\n",
      "EPOCH 1560 Train cost : 0.13484711 | val cost : 0.13567681\n",
      "EPOCH 1600 Train cost : 0.18023396 | val cost : 0.18425181\n",
      "EPOCH 1640 Train cost : 0.10559823 | val cost : 0.10777606\n",
      "EPOCH 1680 Train cost : 0.0972089 | val cost : 0.09924666\n",
      "EPOCH 1720 Train cost : 0.08992402 | val cost : 0.09179463\n",
      "EPOCH 1760 Train cost : 0.08317016 | val cost : 0.08482133\n",
      "EPOCH 1800 Train cost : 0.07677702 | val cost : 0.0781785\n",
      "EPOCH 1840 Train cost : 0.07157289 | val cost : 0.07239371\n",
      "EPOCH 1880 Train cost : 0.05934525 | val cost : 0.06005482\n",
      "EPOCH 1920 Train cost : 0.05039396 | val cost : 0.05073205\n",
      "EPOCH 1960 Train cost : 0.04494585 | val cost : 0.04520199\n",
      "EPOCH 2000 Train cost : 0.04059086 | val cost : 0.04076646\n",
      "EPOCH 2040 Train cost : 0.03684539 | val cost : 0.03695559\n",
      "EPOCH 2080 Train cost : 0.03355602 | val cost : 0.03360777\n",
      "EPOCH 2120 Train cost : 0.03065225 | val cost : 0.03064913\n",
      "EPOCH 2160 Train cost : 0.02808785 | val cost : 0.02804069\n",
      "EPOCH 2200 Train cost : 0.02582341 | val cost : 0.02574186\n",
      "EPOCH 2240 Train cost : 0.0238234 | val cost : 0.02371319\n",
      "EPOCH 2280 Train cost : 0.02205585 | val cost : 0.02192464\n",
      "EPOCH 2320 Train cost : 0.02049232 | val cost : 0.02034455\n",
      "EPOCH 2360 Train cost : 0.01910619 | val cost : 0.01893936\n",
      "EPOCH 2400 Train cost : 0.01787389 | val cost : 0.01768877\n",
      "EPOCH 2440 Train cost : 0.01677397 | val cost : 0.01656981\n",
      "EPOCH 2480 Train cost : 0.01578846 | val cost : 0.01556713\n",
      "EPOCH 2520 Train cost : 0.0149019 | val cost : 0.01466665\n",
      "EPOCH 2560 Train cost : 0.01410111 | val cost : 0.01385457\n",
      "EPOCH 2600 Train cost : 0.01337476 | val cost : 0.01311922\n",
      "EPOCH 2640 Train cost : 0.01271337 | val cost : 0.01245074\n",
      "EPOCH 2680 Train cost : 0.01210864 | val cost : 0.01184075\n",
      "EPOCH 2720 Train cost : 0.01155425 | val cost : 0.01128218\n",
      "EPOCH 2760 Train cost : 0.01104434 | val cost : 0.01076898\n",
      "EPOCH 2800 Train cost : 0.01057383 | val cost : 0.01029605\n",
      "EPOCH 2840 Train cost : 0.01013815 | val cost : 0.00985893\n",
      "EPOCH 2880 Train cost : 0.00973388 | val cost : 0.0094538\n",
      "EPOCH 2920 Train cost : 0.00935789 | val cost : 0.00907737\n",
      "EPOCH 2960 Train cost : 0.00900732 | val cost : 0.00872678\n",
      "EPOCH 3000 Train cost : 0.00867975 | val cost : 0.00839955\n",
      "EPOCH 3040 Train cost : 0.00837306 | val cost : 0.00809348\n",
      "EPOCH 3080 Train cost : 0.00808537 | val cost : 0.00780662\n",
      "EPOCH 3120 Train cost : 0.00781501 | val cost : 0.00753726\n",
      "EPOCH 3160 Train cost : 0.00756051 | val cost : 0.00728393\n",
      "EPOCH 3200 Train cost : 0.00732051 | val cost : 0.00704527\n",
      "EPOCH 3240 Train cost : 0.0070939 | val cost : 0.00682012\n",
      "EPOCH 3280 Train cost : 0.00687961 | val cost : 0.00660741\n",
      "EPOCH 3320 Train cost : 0.00667668 | val cost : 0.00640617\n",
      "EPOCH 3360 Train cost : 0.00648426 | val cost : 0.00621557\n",
      "EPOCH 3400 Train cost : 0.00630158 | val cost : 0.0060348\n",
      "EPOCH 3440 Train cost : 0.00612794 | val cost : 0.00586317\n",
      "EPOCH 3480 Train cost : 0.00596273 | val cost : 0.00570002\n",
      "EPOCH 3520 Train cost : 0.00580537 | val cost : 0.00554475\n",
      "EPOCH 3560 Train cost : 0.00565537 | val cost : 0.00539684\n",
      "EPOCH 3600 Train cost : 0.00551222 | val cost : 0.0052558\n",
      "EPOCH 3640 Train cost : 0.00537548 | val cost : 0.00512117\n",
      "EPOCH 3680 Train cost : 0.00524476 | val cost : 0.00499255\n",
      "EPOCH 3720 Train cost : 0.00511969 | val cost : 0.00486956\n",
      "EPOCH 3760 Train cost : 0.00499993 | val cost : 0.00475187\n",
      "EPOCH 3800 Train cost : 0.00488515 | val cost : 0.00463914\n",
      "EPOCH 3840 Train cost : 0.00477507 | val cost : 0.00453109\n",
      "EPOCH 3880 Train cost : 0.0046694 | val cost : 0.00442744\n",
      "EPOCH 3920 Train cost : 0.0045679 | val cost : 0.00432794\n",
      "EPOCH 3960 Train cost : 0.00447034 | val cost : 0.00423236\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network.train([X_train.shape[0],8, y_train.shape[0]], iterations=4000, learning_rate=0.1, adam_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neural_network.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 1, 0, 4, 4, 2, 7, 6, 3, 1, 1, 1, 4, 7, 7, 5, 6, 6, 5, 5, 7,\n",
       "       4, 1, 5, 4, 7, 3, 3, 7, 0, 1, 4, 2, 2, 4, 6, 1, 2, 0, 0, 7, 1, 2,\n",
       "       4, 0, 4, 6, 1, 5, 1, 3, 1, 7, 7, 2, 1, 7, 6, 4, 6, 7, 7, 7, 2, 5,\n",
       "       1, 6, 4, 3, 1, 3, 3, 7, 1, 4, 3, 4, 6, 5, 0, 1, 7, 3, 1, 7, 5, 2,\n",
       "       5, 5, 4, 4, 3, 6, 3, 4, 4, 4, 1, 3, 7, 5, 0, 4, 3, 1, 1, 0, 1, 1,\n",
       "       4, 3, 3, 5, 3, 5, 3, 5, 3, 1, 3, 3, 3, 6, 4, 0, 1, 6, 4, 7, 2, 4,\n",
       "       7, 1, 3, 4, 3, 5, 2, 2, 4, 1, 0, 4, 0, 6, 0, 6, 1, 5, 0, 1, 0, 6,\n",
       "       2, 3, 6, 1, 1, 6, 2, 3, 1, 6, 4, 7, 3, 1, 4, 7, 3, 4, 7, 6, 7, 1,\n",
       "       7, 2, 2, 1, 1, 5, 5, 1, 3, 3, 6, 5, 0, 6, 6, 0, 4, 1, 7, 1, 3, 7,\n",
       "       0, 2, 1, 7, 1, 0, 1, 4, 6, 7, 7, 3, 4, 0, 2, 2, 0, 2, 0, 1, 0, 4,\n",
       "       7, 3, 4, 7, 5, 0, 4, 7, 3, 7, 1, 0, 7, 3, 7, 0, 4, 3, 3, 0, 6, 0,\n",
       "       2, 4, 0, 5, 0, 6, 5, 1, 4, 2, 7, 4, 7, 0, 4, 3, 6, 7, 3, 5, 0, 2,\n",
       "       5, 3, 0, 7, 7, 5, 2, 0, 3, 3, 0, 6, 0, 3, 5, 0, 2, 3, 6, 3, 1, 2,\n",
       "       6, 2, 3, 6, 0, 2, 0, 6, 3, 2, 7, 2, 3, 2, 2, 0, 3, 5, 7, 3, 2, 2,\n",
       "       0, 3, 0, 2, 4, 3, 0, 3, 6, 4, 6, 7, 2, 4, 5, 3, 6, 6, 6, 0, 5, 6,\n",
       "       4, 5, 4, 6, 4, 7, 0, 6, 2, 1, 2, 0, 0, 3, 1, 0, 7, 7, 3, 6, 6, 5,\n",
       "       6, 2, 1, 3, 4, 5, 3, 2, 1, 3, 2, 2, 6, 2, 1, 7, 0, 3, 4, 2, 2, 7,\n",
       "       1, 4, 6, 6, 6, 6, 2, 4, 2, 0, 3, 7, 7, 0, 4, 3, 4, 0, 5, 5, 4, 5,\n",
       "       2, 2, 6, 7, 4, 1, 2, 6, 7, 7, 7, 5, 3, 4, 6, 6, 1, 5, 5, 5, 2, 6,\n",
       "       5, 2, 7, 2, 3, 2, 3, 4, 5, 1, 3, 0, 2, 5, 4, 5, 3, 2, 3, 5, 1, 6,\n",
       "       5, 4, 7, 3, 7, 4, 1, 4, 0, 2, 5, 1, 3, 1, 6, 4, 6, 4, 0, 2, 3, 2,\n",
       "       2, 0, 5, 5, 0, 7, 7, 7, 1, 2, 5, 5, 2, 1, 4, 6, 3, 1, 7, 0, 2, 7,\n",
       "       2, 2, 0, 0, 0, 7, 2, 0, 6, 6, 2, 6, 3, 4, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred.T, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 1, 0, 4, 4, 2, 7, 6, 3, 1, 1, 1, 4, 7, 7, 5, 6, 6, 5, 5, 7,\n",
       "       4, 1, 5, 4, 7, 3, 3, 7, 0, 1, 4, 2, 2, 4, 6, 1, 2, 0, 0, 7, 1, 2,\n",
       "       4, 0, 4, 6, 1, 5, 1, 3, 1, 7, 7, 2, 1, 7, 6, 4, 6, 7, 7, 7, 2, 5,\n",
       "       1, 6, 4, 3, 1, 3, 3, 7, 1, 4, 3, 4, 6, 5, 0, 1, 7, 3, 1, 7, 5, 2,\n",
       "       5, 5, 4, 4, 3, 6, 3, 4, 4, 4, 1, 3, 7, 5, 0, 4, 3, 1, 1, 0, 1, 1,\n",
       "       4, 3, 3, 5, 3, 5, 3, 5, 3, 1, 3, 3, 3, 6, 4, 0, 1, 6, 4, 7, 2, 4,\n",
       "       7, 1, 3, 4, 3, 5, 2, 2, 4, 1, 0, 4, 0, 6, 0, 6, 1, 5, 0, 1, 0, 6,\n",
       "       2, 3, 6, 1, 1, 6, 2, 3, 1, 6, 4, 7, 3, 1, 4, 7, 3, 4, 7, 6, 7, 1,\n",
       "       7, 2, 2, 1, 1, 5, 5, 1, 3, 3, 6, 5, 0, 6, 6, 0, 4, 1, 7, 1, 3, 7,\n",
       "       0, 2, 1, 7, 1, 0, 1, 4, 6, 7, 7, 3, 4, 0, 2, 2, 0, 2, 0, 1, 0, 4,\n",
       "       7, 3, 4, 7, 5, 0, 4, 7, 3, 7, 1, 0, 7, 3, 7, 0, 4, 3, 3, 0, 6, 0,\n",
       "       2, 4, 0, 5, 0, 6, 5, 1, 4, 2, 7, 4, 7, 0, 4, 3, 6, 7, 3, 5, 0, 2,\n",
       "       5, 3, 0, 7, 7, 5, 2, 0, 3, 3, 0, 6, 0, 3, 5, 0, 2, 3, 6, 3, 1, 2,\n",
       "       6, 2, 3, 6, 0, 2, 0, 6, 3, 2, 7, 2, 3, 2, 2, 0, 3, 5, 7, 3, 2, 2,\n",
       "       0, 3, 0, 2, 4, 3, 0, 3, 6, 4, 6, 7, 2, 4, 5, 3, 6, 6, 6, 0, 5, 6,\n",
       "       4, 5, 4, 6, 4, 7, 0, 6, 2, 1, 2, 0, 0, 3, 1, 0, 7, 7, 3, 6, 6, 5,\n",
       "       6, 2, 1, 3, 4, 5, 3, 2, 1, 3, 2, 2, 6, 2, 1, 7, 0, 3, 4, 2, 2, 7,\n",
       "       1, 4, 6, 6, 6, 6, 2, 4, 2, 0, 3, 7, 7, 0, 4, 3, 4, 0, 5, 5, 4, 5,\n",
       "       2, 2, 6, 7, 4, 1, 2, 6, 7, 7, 7, 5, 3, 4, 6, 6, 1, 5, 5, 5, 2, 6,\n",
       "       5, 2, 7, 2, 3, 2, 3, 4, 5, 1, 3, 0, 2, 5, 4, 5, 3, 2, 3, 5, 1, 6,\n",
       "       5, 4, 7, 3, 7, 4, 1, 4, 0, 2, 5, 1, 3, 1, 6, 4, 6, 4, 0, 2, 3, 2,\n",
       "       2, 0, 5, 5, 0, 7, 7, 7, 1, 2, 5, 5, 2, 1, 4, 6, 3, 1, 7, 0, 2, 7,\n",
       "       2, 2, 0, 0, 0, 7, 2, 0, 6, 6, 2, 6, 3, 4, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_val.T, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_pred.T, axis = 1), np.argmax(y_val.T, axis = 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
