{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(value):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Value -> Matrix of values\n",
    "    return:\n",
    "        Z1 -> Matrix after passing through activation function\n",
    "    \"\"\"\n",
    "    z1 = np.maximum(0, value)\n",
    "    idx = np.nonzero(z1)\n",
    "    z1[idx] = 1\n",
    "    return z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(value):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Value -> Matrix of values\n",
    "    return:\n",
    "        Z1 -> Matrix after passing through sigmoid activation function        \n",
    "    \"\"\"\n",
    "    return (1/(1 + np.exp(-value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(dim):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    dim:\n",
    "        array containing dimensions of the layers\n",
    "    \n",
    "    return:\n",
    "        python dict with parameters\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    L = len(dim)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(dim[l], dim[l-1]) * 0.01\n",
    "        parameters[\"b\" + str(l)] = np.ones((dim[l], 1)) * 0.01\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the forward prop\n",
    "    \n",
    "    Args:\n",
    "        A -> Matrix from the previous layer\n",
    "        W -> Weights matrix from this layer\n",
    "        b -> bias vector from this layer\n",
    "    \n",
    "    return:\n",
    "        Z -> dot product result\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    Z = W @ A + b\n",
    "    \n",
    "    cache = (W, A, b)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we will call propagate then the respective activation function, which will return us the A/$\\hat{Y}$ and we will use it and the cache to make calcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perceptron Learning Algorithm**\n",
    "\n",
    "```python\n",
    "function rna-learning(training-examples)\n",
    "    network <- initialize_weights(randomly)\n",
    "    start loop\n",
    "        for each example in training_examples do\n",
    "            network_out = rna_output(network, example)\n",
    "            example_err = actual_out - network_out\n",
    "            Atualiza pesos usando a Regra Delta\n",
    "        end for\n",
    "    end loop quando todos os exemplos forem corretamente preditos ou critÃ©rios de parada forem atingidos\n",
    "return network\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_computation(A, Y):\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    loss = np.dot(Y, np.log(A).T) + np.dot((1-Y), np.log(1-A).T)\n",
    "    cost = -1/m*np.sum(loss)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    one_hot = np.zeros([len(x), 8])\n",
    "    for i in enumerate(x):\n",
    "        one_hot[(i[0], i[1])] = 1\n",
    "    return one_hot\n",
    "\n",
    "def rand():\n",
    "    return round(random.randint(0,1) + random.uniform(-0.1, 0.1),4)\n",
    "\n",
    "total_data = 1000\n",
    "data_X = np.zeros((total_data,3), dtype=np.float32)\n",
    "data_y = np.zeros(total_data, dtype=np.int8)\n",
    "\n",
    "for i in range(total_data):\n",
    "    val = np.array([rand(), rand(), rand()])\n",
    "    data_X[i] = val\n",
    "\n",
    "    code = np.array([round(val[0]), round(val[1]), round(val[2])])\n",
    "    label = np.array([code[0]*4 + code[1]*2 + code[2]])\n",
    "    data_y[i] = label\n",
    "\n",
    "data_y = one_hot_encode(data_y)\n",
    "\n",
    "X_train, val_X = np.split(data_X, 2)\n",
    "y_train, val_y = np.split(data_y, 2)\n",
    "\n",
    "val_X, test_X = np.split(val_X, 2)\n",
    "val_y, test_y = np.split(val_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 3), (500, 8))"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "0.8045\n",
      "0.0001\n",
      "0.03175\n",
      "0.0001\n",
      "0.021\n",
      "0.0001\n",
      "0.0245\n",
      "0.0001\n",
      "0.01725\n",
      "0.0001\n",
      "0.027749999999999997\n",
      "0.0001\n",
      "0.09975\n",
      "0.0001\n",
      "0.0145\n",
      "0.0001\n",
      "0.0805\n",
      "0.0001\n",
      "0.06924999999999999\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "network = initialize_parameters([3,8])\n",
    "iterations = 100000\n",
    "learning_rate = 0.0001\n",
    "m = X_train.shape[0]\n",
    "print(m)\n",
    "for i in range(iterations):\n",
    "    A, cache = propagate(X_train.T, network[\"W1\"], network[\"b1\"])\n",
    "    y_hat = step_function(A)\n",
    "    if i % 10000 == 0:\n",
    "        cost = mean_squared_error(y_train, y_hat.T)\n",
    "        print(cost)\n",
    "        print(learning_rate)\n",
    "    \n",
    "    #print(network[\"W1\"].shape, cost.shape, X_train.shape)\n",
    "    dw = (1/m)*(np.dot(X_train.T, ((y_hat-y_train.T).T))).T\n",
    "    db = (1/m)*(np.sum(y_hat-y_train.T)).T\n",
    "    network[\"W1\"] -= learning_rate * dw\n",
    "    network[\"b1\"] -= learning_rate * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = propagate(test_X.T, network[\"W1\"], network[\"b1\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = step_function(y_pred).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 8)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 8)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14950000000000002"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
